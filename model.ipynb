{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3385e3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-07T01:42:14.948726Z",
     "iopub.status.busy": "2025-05-07T01:42:14.948405Z",
     "iopub.status.idle": "2025-05-07T01:42:33.599400Z",
     "shell.execute_reply": "2025-05-07T01:42:33.598544Z"
    },
    "papermill": {
     "duration": 18.656428,
     "end_time": "2025-05-07T01:42:33.601051",
     "exception": false,
     "start_time": "2025-05-07T01:42:14.944623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "# !pip install torchvision\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# !pip install torchmetrics\n",
    "import torchmetrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d1a8f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:42:33.606922Z",
     "iopub.status.busy": "2025-05-07T01:42:33.606061Z",
     "iopub.status.idle": "2025-05-07T01:42:34.407452Z",
     "shell.execute_reply": "2025-05-07T01:42:34.406360Z"
    },
    "papermill": {
     "duration": 0.805731,
     "end_time": "2025-05-07T01:42:34.409220",
     "exception": false,
     "start_time": "2025-05-07T01:42:33.603489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 載入數據\n",
    "#訓練集weights_only用False\n",
    "images = torch.load(\"/kaggle/input/moai-2025-training/train_images.pt\", weights_only = False)\n",
    "labels = pd.read_csv(\"/kaggle/input/moai-2025-training/train_labels.csv\")\n",
    "\n",
    "# 歸一化\n",
    "images = images.float()\n",
    "images = (images - images.min()) / images.max()\n",
    "\n",
    "# 將labels變為tensor類型\n",
    "labels = torch.tensor(labels[\"label\"].values)\n",
    "\n",
    "#合并為一個數據集\n",
    "dataset = TensorDataset(images, labels)\n",
    "\n",
    "# 劃分數據集\n",
    "train_size = int(len(dataset) * 0.8)\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 轉換為dataloader\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 64)\n",
    "\n",
    "#for x, y in train_loader:\n",
    "    #print(x.shape) 發現缺少Channel\n",
    "#for i in range(5):\n",
    "    #print(images[i])\n",
    "print(images.shape) #[60000, 28, 28] 60000個28*28樣本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5aa04e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:42:34.415208Z",
     "iopub.status.busy": "2025-05-07T01:42:34.414389Z",
     "iopub.status.idle": "2025-05-07T01:42:34.436802Z",
     "shell.execute_reply": "2025-05-07T01:42:34.435761Z"
    },
    "papermill": {
     "duration": 0.026637,
     "end_time": "2025-05-07T01:42:34.438114",
     "exception": false,
     "start_time": "2025-05-07T01:42:34.411477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn(\n",
      "  (Model): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "    (10): Linear(in_features=576, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class cnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.Model = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size = 3, padding = 1), # [16, 28, 28] channel, h, w\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # [16, 14, 14]\n",
    "            nn.Conv2d(16, 32, kernel_size = 3, padding = 1), # [32, 14, 14]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), # [32, 7, 7]\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, padding = 1), # [64, 7, 7]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2), #[64, 3, 3]\n",
    "            nn.Flatten(), #展平\n",
    "            nn.Linear(64 * 3 * 3, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, 28, 28) #補上channel(1) 標準格式 : [N, C, H , W]\n",
    "        #N是批次個數, 通常是batch_size, C是channel，黑白是1，彩色是3。H是高，W是寬。\n",
    "        # -1代表自動設batch_size(因為有時侯不夠)\n",
    "        return self.Model(x)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = cnn().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f94ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:42:34.444843Z",
     "iopub.status.busy": "2025-05-07T01:42:34.444040Z",
     "iopub.status.idle": "2025-05-07T01:49:25.761492Z",
     "shell.execute_reply": "2025-05-07T01:49:25.760432Z"
    },
    "papermill": {
     "duration": 411.322717,
     "end_time": "2025-05-07T01:49:25.762980",
     "exception": false,
     "start_time": "2025-05-07T01:42:34.440263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 749, Train Loss: 0.0290, Train Accuracy: 100.00%\n",
      "Epoch 1, Val Loss: 0.0835, Val Accuracy: 97.38%\n",
      "Epoch 2, Batch 749, Train Loss: 0.0578, Train Accuracy: 98.44%\n",
      "Epoch 2, Val Loss: 0.0628, Val Accuracy: 97.92%\n",
      "Epoch 3, Batch 749, Train Loss: 0.0185, Train Accuracy: 100.00%\n",
      "Epoch 3, Val Loss: 0.0440, Val Accuracy: 98.57%\n",
      "Epoch 4, Batch 749, Train Loss: 0.0088, Train Accuracy: 100.00%\n",
      "Epoch 4, Val Loss: 0.0461, Val Accuracy: 98.58%\n",
      "Epoch 5, Batch 749, Train Loss: 0.1208, Train Accuracy: 96.88%\n",
      "Epoch 5, Val Loss: 0.0508, Val Accuracy: 98.47%\n",
      "Epoch 6, Batch 749, Train Loss: 0.0070, Train Accuracy: 100.00%\n",
      "Epoch 6, Val Loss: 0.0396, Val Accuracy: 98.69%\n",
      "Epoch 7, Batch 749, Train Loss: 0.0020, Train Accuracy: 100.00%\n",
      "Epoch 7, Val Loss: 0.0381, Val Accuracy: 98.82%\n",
      "Epoch 8, Batch 749, Train Loss: 0.0033, Train Accuracy: 100.00%\n",
      "Epoch 8, Val Loss: 0.0429, Val Accuracy: 98.79%\n",
      "Epoch 9, Batch 749, Train Loss: 0.0004, Train Accuracy: 100.00%\n",
      "Epoch 9, Val Loss: 0.0408, Val Accuracy: 98.88%\n",
      "Epoch 10, Batch 749, Train Loss: 0.0136, Train Accuracy: 98.44%\n",
      "Epoch 10, Val Loss: 0.0445, Val Accuracy: 98.72%\n",
      "Epoch 11, Batch 749, Train Loss: 0.0622, Train Accuracy: 98.44%\n",
      "Epoch 11, Val Loss: 0.0416, Val Accuracy: 98.81%\n",
      "Epoch 12, Batch 749, Train Loss: 0.0008, Train Accuracy: 100.00%\n",
      "Epoch 12, Val Loss: 0.0449, Val Accuracy: 98.75%\n",
      "Epoch 13, Batch 749, Train Loss: 0.0060, Train Accuracy: 100.00%\n",
      "Epoch 13, Val Loss: 0.0527, Val Accuracy: 98.59%\n",
      "Epoch 14, Batch 749, Train Loss: 0.0002, Train Accuracy: 100.00%\n",
      "Epoch 14, Val Loss: 0.0482, Val Accuracy: 98.81%\n",
      "Epoch 15, Batch 749, Train Loss: 0.0016, Train Accuracy: 100.00%\n",
      "Epoch 15, Val Loss: 0.0449, Val Accuracy: 98.98%\n",
      "Epoch 16, Batch 749, Train Loss: 0.0021, Train Accuracy: 100.00%\n",
      "Epoch 16, Val Loss: 0.0399, Val Accuracy: 99.02%\n",
      "Epoch 17, Batch 749, Train Loss: 0.0018, Train Accuracy: 100.00%\n",
      "Epoch 17, Val Loss: 0.0433, Val Accuracy: 99.06%\n",
      "Epoch 18, Batch 749, Train Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Epoch 18, Val Loss: 0.0459, Val Accuracy: 98.94%\n",
      "Epoch 19, Batch 749, Train Loss: 0.0001, Train Accuracy: 100.00%\n",
      "Epoch 19, Val Loss: 0.0566, Val Accuracy: 98.86%\n",
      "Epoch 20, Batch 749, Train Loss: 0.0072, Train Accuracy: 100.00%\n",
      "Epoch 20, Val Loss: 0.0493, Val Accuracy: 98.98%\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss() # 多分類問題用的Loss Function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #使用adam優化器, 學習率為3e-4\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau( #自動調學習率\n",
    "    optimizer, \n",
    "    mode = 'max', # 監控驗證損失\n",
    "    factor =0.1,  # 學習率衰減係數\n",
    "    patience = 5, # 容忍n個epoch無改善\n",
    "    verbose = True, # 打印調整日誌\n",
    "    min_lr = 1e-3 # 最小學習率\n",
    ")\n",
    "\n",
    "for x in range(20):\n",
    "    model.train() #進入訓練模式\n",
    "    for batch_i, (img, lab) in enumerate(train_loader): #每一次循環會返回索引和數據\n",
    "        optimizer.zero_grad() #清空先前累積的梯度\n",
    "        img = img.to(device)\n",
    "        lab = lab.to(device)\n",
    "        #將img和lab移動到先前指定的計算設備\n",
    "        outputs = model(img)\n",
    "        loss = loss_function(outputs, lab) #計算loss\n",
    "        loss.backward() #用反向傳播計算梯度\n",
    "        optimizer.step() #更新Weight\n",
    "        pred = outputs.argmax(dim = 1) #dim = 1代表批次中的每個樣本中的10個類別選擇最高分的索引 (橫看)\n",
    "        #dim = 0是縱看\n",
    "        train_loss = float(loss) #將loss由tensor變回float方便進行運算\n",
    "        train_acc = accuracy_score(lab.numpy(), pred.numpy()) #必須使用cpu和numpy陣列 / list\n",
    "    print(f\"Epoch {x + 1}, Batch {batch_i}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc * 100:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    val_pred = []\n",
    "    val_lab = []\n",
    "    val_loss = 0\n",
    "    sample = 0\n",
    "    average_val_loss = 0\n",
    "    with torch.no_grad(): #關掉梯度計算\n",
    "        for img, lab in val_loader:\n",
    "            img = img.to(device)\n",
    "            outputs = model(img)\n",
    "            val_pred.extend(outputs.argmax(dim = 1).cpu().numpy()) #將所有pred合在一起\n",
    "            val_lab.extend(lab.numpy())\n",
    "            val_loss += float(loss_function(outputs, lab)) * img.size(0) # img.size(0)是當前batch的size\n",
    "            sample += img.size(0)\n",
    "    val_acc = accuracy_score(val_lab, val_pred)\n",
    "    average_val_loss = float(val_loss / sample)\n",
    "    scheduler.step(average_val_loss)\n",
    "    print(f\"Epoch {x + 1}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {val_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b38ba296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-07T01:49:25.772455Z",
     "iopub.status.busy": "2025-05-07T01:49:25.772110Z",
     "iopub.status.idle": "2025-05-07T01:49:28.955584Z",
     "shell.execute_reply": "2025-05-07T01:49:28.954568Z"
    },
    "papermill": {
     "duration": 3.189996,
     "end_time": "2025-05-07T01:49:28.957261",
     "exception": false,
     "start_time": "2025-05-07T01:49:25.767265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#測試集weights_only用True\n",
    "test_images = torch.load(\"/kaggle/input/moai-2025-training/test_images.pt\", weights_only = True)\n",
    "\n",
    "test_images = test_images.float()\n",
    "tset_images = (test_images - test_images.min()) / test_images.max()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_images = test_images.to(device)\n",
    "    outputs = model(test_images)\n",
    "    pred = outputs.argmax(dim = 1)\n",
    "    \n",
    "df_test = pd.DataFrame({\"label\": pred.cpu().numpy()}) #一定要用cpu及numpy / list\n",
    "df_test.to_csv(\"submission.csv\", index_label=\"id\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11751604,
     "sourceId": 98462,
     "sourceType": "competition"
    },
    {
     "datasetId": 7329881,
     "sourceId": 11678542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 441.317967,
   "end_time": "2025-05-07T01:49:31.677178",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-07T01:42:10.359211",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
