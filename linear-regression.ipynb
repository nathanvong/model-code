{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98462,"databundleVersionId":11751604,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":11709406,"sourceType":"datasetVersion","datasetId":7349767}],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\nimport torch\nfrom torch import optim\nfrom torch import nn\nfrom torch.utils.data import TensorDataset, DataLoader, random_split\nfrom tqdm import tqdm\nimport torch.optim.lr_scheduler as lr_scheduler\n\n# !pip install torchvision\nimport torchvision\n\nimport torch.nn.functional as F\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\n# !pip install torchmetrics\nimport torchmetrics\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:13:51.838786Z","iopub.execute_input":"2025-05-07T08:13:51.839147Z","iopub.status.idle":"2025-05-07T08:14:05.171214Z","shell.execute_reply.started":"2025-05-07T08:13:51.839118Z","shell.execute_reply":"2025-05-07T08:14:05.170296Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/linear-dataset/linear_dataset.csv\")\nx, y = df.iloc[:, 0], df.iloc[:, 1]\nx = (x - x.min()) / x.max()\ny = (y - y.min()) / y.max()\n\nx = np.array(x)\nx = x.reshape(len(x), 1) # 化身多行一列的二維數組\n\n\nmodel = LinearRegression()\nmodel.fit(x, y)\nprint(model.score(x, y))\n\npred = np.array([1, 2])\npred = pred.reshape(2, 1)\n\nans = model.predict(pred)\nprint(np.round(ans * (pred.max() - pred.min()) + pred.min()).astype(int)) #反向歸一化及四捨五入, 變回int\n#反向歸一化公式 : val * (max - min) + min","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:14:25.375639Z","iopub.execute_input":"2025-05-07T08:14:25.376756Z","iopub.status.idle":"2025-05-07T08:14:25.420926Z","shell.execute_reply.started":"2025-05-07T08:14:25.376717Z","shell.execute_reply":"2025-05-07T08:14:25.419867Z"}},"outputs":[{"name":"stdout","text":"0.997599962106742\n[2 3]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#neural network version\nimg, lab = df.iloc[:, 0], df.iloc[:, 1]\n\nimg = torch.tensor(img.values)\nlab = torch.tensor(lab.values)\n\nimg = img.float()\nlab = lab.float()\nimg = (img - img.min()) / img.max()\nlab = (lab - lab.min()) / lab.max()\n\nimg = img.reshape(len(img), 1) #輸入格式必須為(batch_size, 特徵數)\nlab = lab.reshape(len(lab), 1)\ndataset = TensorDataset(img, lab)\n\ntrain_size = int(len(dataset) * 0.8)\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\ntrain_loader = DataLoader(train_dataset, batch_size = 16, shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 16, shuffle = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:31:01.979820Z","iopub.execute_input":"2025-05-07T08:31:01.980146Z","iopub.status.idle":"2025-05-07T08:31:01.989430Z","shell.execute_reply.started":"2025-05-07T08:31:01.980120Z","shell.execute_reply":"2025-05-07T08:31:01.988472Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"class network(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear1 = nn.Linear(1, 16)\n        self.linear2 = nn.Linear(16, 1)\n    def forward(self, x):\n        x = self.linear2(self.linear1(x))\n        return x\ndevice = torch.device(\"cpu\")\nmodel = network().to(device)\nprint(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:21:59.177235Z","iopub.execute_input":"2025-05-07T08:21:59.177550Z","iopub.status.idle":"2025-05-07T08:21:59.185089Z","shell.execute_reply.started":"2025-05-07T08:21:59.177526Z","shell.execute_reply":"2025-05-07T08:21:59.184226Z"}},"outputs":[{"name":"stdout","text":"network(\n  (linear1): Linear(in_features=1, out_features=16, bias=True)\n  (linear2): Linear(in_features=16, out_features=1, bias=True)\n)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nloss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n\nscheduler = lr_scheduler.ReduceLROnPlateau( #自動調學習率\n    optimizer, \n    mode = 'max', # 監控驗證損失\n    factor = 0.1,  # 學習率衰減係數\n    patience = 5, # 容忍n個epoch無改善\n    verbose = True, # 打印調整日誌\n    min_lr = 1e-3 # 最小學習率\n)\n\nfor i in range(5):\n    model.train()\n    for (images, labels) in train_loader:\n        optimizer.zero_grad()\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        loss = loss_function(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        pred = outputs.argmax(dim = 1)\n        mse = mean_squared_error(labels.numpy(), pred.detach().numpy())\n        print(mse)\n    model.eval()\n    total_loss = 0\n    sample = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            total_loss += float(loss_function(outputs, labels)) * img.size(0)\n            sample = img.size(0)\n        scheduler.step(total_loss / sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T08:34:49.883886Z","iopub.execute_input":"2025-05-07T08:34:49.884199Z","iopub.status.idle":"2025-05-07T08:34:50.270070Z","shell.execute_reply.started":"2025-05-07T08:34:49.884175Z","shell.execute_reply":"2025-05-07T08:34:50.269099Z"}},"outputs":[{"name":"stdout","text":"0.20086845340494958\n0.2653461950382702\n0.46587647327757453\n0.2569844284505217\n0.3340870072850836\n0.422042505340527\n0.42211429892979924\n0.22254482355047134\n0.24140662054382817\n0.23988352052929754\n0.23091999107413672\n0.40069334192821626\n0.4124065537368734\n0.3492942860649997\n0.3214760539791999\n0.3319600892970146\n0.3081389532996903\n0.25391199622896365\n0.23928998499770565\n0.18805377511636384\n0.2991042832344038\n0.28334309326501417\n0.43613888774309256\n0.3225289861962862\n0.3848083122913334\n0.3412799239781252\n0.2682485089907954\n0.3632181425261916\n0.3200700471224251\n0.35118683287438407\n0.33725391837122115\n0.19543826448688734\n0.35416416150263946\n0.31681371539170794\n0.29150325066146054\n0.3635321637842257\n0.3136445443535252\n0.2896963708503669\n0.39988765833335826\n0.4044819847473007\n0.3776960310244744\n0.3397649182194974\n0.23937397969960084\n0.2929444536976812\n0.3722609822688905\n0.3398741820785777\n0.2901657248181064\n0.37114460745685185\n0.3814994147024642\n0.35531493066810493\n0.31002885213725523\n0.35767508344773336\n0.32843218372646366\n0.3340338326428841\n0.18295287038135893\n0.3377626085356625\n0.24293367660025877\n0.20756042537893957\n0.2661449384550405\n0.30489375164086346\n0.4476491927286874\n0.30867502892463106\n0.3790673933347763\n0.20432457352079914\n0.33595584659805366\n0.33587511652447166\n0.2560536138007181\n0.4067435528678393\n0.36261117198624226\n0.17730654646559313\n0.30762001340676737\n0.3317656660615249\n0.3511029630823077\n0.38762499763339703\n0.3897945400736522\n0.33774455260834413\n0.2989999989155924\n0.30603247458671196\n0.4434440462614346\n0.2656238892683016\n0.3631826210016288\n0.3497186313997743\n0.4026170910095104\n0.33621368874675894\n0.2509281448296438\n0.32820126183990705\n0.3373282591028579\n0.3416497178951795\n0.28137722705350643\n0.32508431414110883\n0.24825772318385259\n0.22160755046500036\n0.26025361721634976\n0.324135330956005\n0.3806877589550256\n0.32460498905331986\n0.37433552769610323\n0.3143468449960459\n0.5328921907068129\n0.296126455894429\n0.2968506520958861\n0.26546080338289385\n0.35990998512653805\n0.25116504526045125\n0.39187398296341636\n0.27352964347511544\n0.31591917407131753\n0.4086397708096957\n0.3922666146051492\n0.1930872992254415\n0.2701551366012833\n0.45048517941871985\n0.3754577395635569\n0.34460359798961854\n0.34093920224884056\n0.45111695247737227\n0.2810972251442317\n0.33132301265622455\n0.2896473065312263\n0.3005989978537784\n0.371050078229016\n0.1493013603633737\n0.28873470931812945\n0.36442556743646787\n0.3522681091243964\n0.3539888406368668\n0.38558847862824824\n0.3340228485730123\n0.17991771149657973\n0.331479442877183\n0.33197863708921066\n0.319830952616925\n0.29008319397568816\n0.25990107040989596\n0.30858255653281697\n0.31864622081018246\n0.22339718727254126\n0.4020170001299146\n0.35116804521643963\n0.23021439211007189\n0.42224507889503565\n0.2597215871172308\n0.2880088790174071\n0.42841741070670636\n0.4493471076475582\n0.2522020362934565\n0.19843955800442525\n0.4491562671132279\n0.34494822550705756\n0.27548220756896197\n0.3823076984717589\n0.23890493016934508\n0.3304716438929834\n0.2686782007957598\n0.19453764090919942\n0.26868243924688473\n0.336738424860736\n0.43001283477687524\n0.3576510224084003\n0.3816850240988387\n0.3291187667759685\n0.20553300024211868\n0.22356354659695818\n0.3251781875177362\n0.2565052213287242\n0.3536614425976652\n0.32283046649000224\n0.3806567669820093\n0.3012695401285314\n0.3609365561317134\n0.3428492569129798\n0.22950085295896722\n0.349107105924532\n0.23008080782384302\n0.4102347888091685\n0.27210343251129354\n0.3403423025174809\n0.34296486333193854\n0.3035137149348806\n0.36916065858448743\n0.26676821749544166\n0.47886154857746954\n0.39932256044456554\n0.3388224219492931\n0.2287278390351027\n0.3935689140300994\n0.4072874521288891\n0.3690273677441921\n0.28882063669879354\n0.2745098123595477\n0.3051527261055171\n0.34405600842258266\n0.28405106320753337\n0.2685643447588294\n0.24925952162888032\n0.4121073926687896\n0.29890177049825334\n0.2902808109976398\n0.42733887387614466\n0.3384149577454714\n0.3739890019005782\n0.35213315102263454\n0.31031730064658647\n0.31112065942072653\n0.3593112975837473\n0.15014023335919363\n0.31607931411918994\n0.4043895959670708\n0.4158714873392626\n0.3042484485003874\n0.278222567649869\n0.4014976555338292\n0.31142743302074943\n0.32595242659834334\n0.44927012700694663\n0.3541041947964038\n0.3312905236509059\n0.3622877725668281\n0.27470971467079164\n0.3930718330461223\n0.3084939445461076\n0.2523016934268557\n0.2139258204575104\n0.3766843542235719\n0.30511549573879504\n0.32364532196242474\n0.3546838604259609\n0.42529434200370353\n0.30402145933307223\n0.2634717487969665\n0.24706947152871672\n0.3021539135205484\n0.3854399958447921\n0.29788326563854634\n0.3342261035656777\n0.2935353503584058\n0.31833604210879585\n0.2881285102771288\n0.31964616273853996\n0.4131088370299137\n0.27372837082008294\n0.4408475611282803\n0.21852857009030743\n0.3508827258905523\n0.25060547096436375\n0.21449084506529384\n0.36335175504463313\n0.3428483094958894\n0.2971909712927632\n0.23722606136251473\n","output_type":"stream"}],"execution_count":28}]}